{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.927007299270073,
  "eval_steps": 500,
  "global_step": 510,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.19464720194647203,
      "grad_norm": 22.85897445678711,
      "learning_rate": 0.00019647058823529413,
      "loss": 3.632,
      "step": 10
    },
    {
      "epoch": 0.38929440389294406,
      "grad_norm": 18.423015594482422,
      "learning_rate": 0.00019254901960784316,
      "loss": 1.2495,
      "step": 20
    },
    {
      "epoch": 0.583941605839416,
      "grad_norm": 8.399713516235352,
      "learning_rate": 0.00018862745098039216,
      "loss": 0.657,
      "step": 30
    },
    {
      "epoch": 0.7785888077858881,
      "grad_norm": 10.048810005187988,
      "learning_rate": 0.0001847058823529412,
      "loss": 0.5346,
      "step": 40
    },
    {
      "epoch": 0.9732360097323601,
      "grad_norm": 151.66082763671875,
      "learning_rate": 0.00018196078431372548,
      "loss": 0.5299,
      "step": 50
    },
    {
      "epoch": 1.167883211678832,
      "grad_norm": 7.510385990142822,
      "learning_rate": 0.0001780392156862745,
      "loss": 0.4253,
      "step": 60
    },
    {
      "epoch": 1.3625304136253042,
      "grad_norm": 6.394371032714844,
      "learning_rate": 0.00017411764705882354,
      "loss": 0.3872,
      "step": 70
    },
    {
      "epoch": 1.557177615571776,
      "grad_norm": 7.0201945304870605,
      "learning_rate": 0.00017019607843137254,
      "loss": 0.4,
      "step": 80
    },
    {
      "epoch": 1.7518248175182483,
      "grad_norm": 5.753494739532471,
      "learning_rate": 0.00016627450980392157,
      "loss": 0.3791,
      "step": 90
    },
    {
      "epoch": 1.94647201946472,
      "grad_norm": 6.302947044372559,
      "learning_rate": 0.0001623529411764706,
      "loss": 0.3564,
      "step": 100
    },
    {
      "epoch": 2.1411192214111923,
      "grad_norm": 5.843056678771973,
      "learning_rate": 0.0001584313725490196,
      "loss": 0.316,
      "step": 110
    },
    {
      "epoch": 2.335766423357664,
      "grad_norm": 6.424182415008545,
      "learning_rate": 0.00015450980392156863,
      "loss": 0.3249,
      "step": 120
    },
    {
      "epoch": 2.5304136253041363,
      "grad_norm": 5.972605228424072,
      "learning_rate": 0.00015058823529411766,
      "loss": 0.3006,
      "step": 130
    },
    {
      "epoch": 2.7250608272506085,
      "grad_norm": 10.947669982910156,
      "learning_rate": 0.00014666666666666666,
      "loss": 0.3146,
      "step": 140
    },
    {
      "epoch": 2.9197080291970803,
      "grad_norm": 6.6670660972595215,
      "learning_rate": 0.0001427450980392157,
      "loss": 0.3309,
      "step": 150
    },
    {
      "epoch": 3.1143552311435525,
      "grad_norm": 5.522458076477051,
      "learning_rate": 0.00013882352941176472,
      "loss": 0.2814,
      "step": 160
    },
    {
      "epoch": 3.3090024330900243,
      "grad_norm": 6.3676910400390625,
      "learning_rate": 0.00013490196078431375,
      "loss": 0.2748,
      "step": 170
    },
    {
      "epoch": 3.5036496350364965,
      "grad_norm": 6.696939468383789,
      "learning_rate": 0.00013098039215686275,
      "loss": 0.2651,
      "step": 180
    },
    {
      "epoch": 3.6982968369829683,
      "grad_norm": 5.900905132293701,
      "learning_rate": 0.00012705882352941175,
      "loss": 0.274,
      "step": 190
    },
    {
      "epoch": 3.8929440389294405,
      "grad_norm": 6.639902114868164,
      "learning_rate": 0.0001231372549019608,
      "loss": 0.2834,
      "step": 200
    },
    {
      "epoch": 4.087591240875913,
      "grad_norm": 5.494331359863281,
      "learning_rate": 0.00011921568627450981,
      "loss": 0.2499,
      "step": 210
    },
    {
      "epoch": 4.2822384428223845,
      "grad_norm": 8.220526695251465,
      "learning_rate": 0.00011529411764705881,
      "loss": 0.2338,
      "step": 220
    },
    {
      "epoch": 4.476885644768856,
      "grad_norm": 6.968906402587891,
      "learning_rate": 0.00011137254901960786,
      "loss": 0.2489,
      "step": 230
    },
    {
      "epoch": 4.671532846715328,
      "grad_norm": 6.343825817108154,
      "learning_rate": 0.00010745098039215686,
      "loss": 0.2355,
      "step": 240
    },
    {
      "epoch": 4.866180048661801,
      "grad_norm": 6.725374698638916,
      "learning_rate": 0.0001035294117647059,
      "loss": 0.2472,
      "step": 250
    },
    {
      "epoch": 5.0608272506082725,
      "grad_norm": 6.817840099334717,
      "learning_rate": 9.96078431372549e-05,
      "loss": 0.2369,
      "step": 260
    },
    {
      "epoch": 5.255474452554744,
      "grad_norm": 8.312772750854492,
      "learning_rate": 9.568627450980393e-05,
      "loss": 0.2197,
      "step": 270
    },
    {
      "epoch": 5.450121654501217,
      "grad_norm": 6.425045013427734,
      "learning_rate": 9.176470588235295e-05,
      "loss": 0.2095,
      "step": 280
    },
    {
      "epoch": 5.644768856447689,
      "grad_norm": 7.308022499084473,
      "learning_rate": 8.784313725490196e-05,
      "loss": 0.2064,
      "step": 290
    },
    {
      "epoch": 5.839416058394161,
      "grad_norm": 8.767561912536621,
      "learning_rate": 8.392156862745099e-05,
      "loss": 0.2081,
      "step": 300
    },
    {
      "epoch": 6.034063260340632,
      "grad_norm": 6.444986343383789,
      "learning_rate": 8e-05,
      "loss": 0.1975,
      "step": 310
    },
    {
      "epoch": 6.228710462287105,
      "grad_norm": 9.093132972717285,
      "learning_rate": 7.607843137254902e-05,
      "loss": 0.1921,
      "step": 320
    },
    {
      "epoch": 6.423357664233577,
      "grad_norm": 6.256903648376465,
      "learning_rate": 7.215686274509804e-05,
      "loss": 0.1844,
      "step": 330
    },
    {
      "epoch": 6.618004866180049,
      "grad_norm": 7.4056572914123535,
      "learning_rate": 6.823529411764707e-05,
      "loss": 0.1847,
      "step": 340
    },
    {
      "epoch": 6.81265206812652,
      "grad_norm": 7.957502365112305,
      "learning_rate": 6.431372549019608e-05,
      "loss": 0.1772,
      "step": 350
    },
    {
      "epoch": 7.007299270072993,
      "grad_norm": 6.845193386077881,
      "learning_rate": 6.03921568627451e-05,
      "loss": 0.188,
      "step": 360
    },
    {
      "epoch": 7.201946472019465,
      "grad_norm": 7.349745273590088,
      "learning_rate": 5.647058823529412e-05,
      "loss": 0.1619,
      "step": 370
    },
    {
      "epoch": 7.396593673965937,
      "grad_norm": 7.038292407989502,
      "learning_rate": 5.254901960784314e-05,
      "loss": 0.1652,
      "step": 380
    },
    {
      "epoch": 7.591240875912408,
      "grad_norm": 7.7898783683776855,
      "learning_rate": 4.862745098039216e-05,
      "loss": 0.1625,
      "step": 390
    },
    {
      "epoch": 7.785888077858881,
      "grad_norm": 7.152511119842529,
      "learning_rate": 4.470588235294118e-05,
      "loss": 0.16,
      "step": 400
    },
    {
      "epoch": 7.980535279805353,
      "grad_norm": 7.99098014831543,
      "learning_rate": 4.0784313725490195e-05,
      "loss": 0.1644,
      "step": 410
    },
    {
      "epoch": 8.175182481751825,
      "grad_norm": 6.214821815490723,
      "learning_rate": 3.686274509803922e-05,
      "loss": 0.1571,
      "step": 420
    },
    {
      "epoch": 8.369829683698297,
      "grad_norm": 7.496259689331055,
      "learning_rate": 3.294117647058824e-05,
      "loss": 0.1406,
      "step": 430
    },
    {
      "epoch": 8.564476885644769,
      "grad_norm": 8.457307815551758,
      "learning_rate": 2.9019607843137258e-05,
      "loss": 0.1476,
      "step": 440
    },
    {
      "epoch": 8.75912408759124,
      "grad_norm": 6.238116264343262,
      "learning_rate": 2.5098039215686277e-05,
      "loss": 0.145,
      "step": 450
    },
    {
      "epoch": 8.953771289537713,
      "grad_norm": 7.148946762084961,
      "learning_rate": 2.1176470588235296e-05,
      "loss": 0.1482,
      "step": 460
    },
    {
      "epoch": 9.148418491484184,
      "grad_norm": 5.65740966796875,
      "learning_rate": 1.7254901960784314e-05,
      "loss": 0.1344,
      "step": 470
    },
    {
      "epoch": 9.343065693430656,
      "grad_norm": 6.902994632720947,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.1296,
      "step": 480
    },
    {
      "epoch": 9.53771289537713,
      "grad_norm": 5.825518608093262,
      "learning_rate": 9.411764705882354e-06,
      "loss": 0.136,
      "step": 490
    },
    {
      "epoch": 9.732360097323602,
      "grad_norm": 6.815798282623291,
      "learning_rate": 5.490196078431373e-06,
      "loss": 0.141,
      "step": 500
    },
    {
      "epoch": 9.927007299270073,
      "grad_norm": 6.3079142570495605,
      "learning_rate": 1.5686274509803923e-06,
      "loss": 0.13,
      "step": 510
    }
  ],
  "logging_steps": 10,
  "max_steps": 510,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6937143593533440.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
