1차 학습
입력 데이터 형식:
{
  "personality": "존칭형",       // "평범형", "존칭형", "하대형", "단답형", "너스레형", "야성형"
  "adventurerType": "전사",     // "전사", "궁수", "마법사", "도적"
  "affectionLevel": 2,          // 0=매우 낮음, 1=낮음, 2=보통, 3=높음, 4=매우 높음
  "visitCount": 2,              // 0=첫방문, 1=초면, 2=아는사이, 3=친구, 4=단골
  "context": {
    "lastResult": 2,            // 0=null(첫방문), 1=실패, 2=성공, 3=대성공
    "lastTypeMatch": 1          // 0=나쁨, 1=보통, 2=좋음 (이전 대여 무기와의 상성)
  }
}

모델: EXAONE-3.5-2.4B 학습률:2e-4 epoch:3 Batch size: 1(accumulation_steps=8로 실제 배치 8) Optimizer: paged_adamw_8bit LR Scheduler:cosine
{'loss': 4.6088, 'grad_norm': 22.80320930480957, 'learning_rate': 0.0001872340425531915, 'epoch': 0.21}
{'loss': 2.2326, 'grad_norm': 23.368995666503906, 'learning_rate': 0.00017304964539007094, 'epoch': 0.42}                                                                                                                  
{'loss': 1.1016, 'grad_norm': 12.463349342346191, 'learning_rate': 0.00015886524822695037, 'epoch': 0.63}                                                                                                                  
{'loss': 0.7764, 'grad_norm': 13.498905181884766, 'learning_rate': 0.0001446808510638298, 'epoch': 0.84}                                                                                                                   
{'loss': 0.6398, 'grad_norm': 11.978620529174805, 'learning_rate': 0.00013191489361702127, 'epoch': 1.05}                                                                                                                  
{'loss': 0.5849, 'grad_norm': 10.862421989440918, 'learning_rate': 0.00011773049645390071, 'epoch': 1.26}                                                                                                                  
{'loss': 0.519, 'grad_norm': 9.910893440246582, 'learning_rate': 0.00010354609929078013, 'epoch': 1.47}                                                                                                                    
{'loss': 0.5099, 'grad_norm': 12.074780464172363, 'learning_rate': 8.936170212765958e-05, 'epoch': 1.68}                                                                                                                   
{'loss': 0.4811, 'grad_norm': 388.5758972167969, 'learning_rate': 8.085106382978723e-05, 'epoch': 1.88}                                                                                                                    
{'loss': 0.4379, 'grad_norm': 11.574589729309082, 'learning_rate': 6.666666666666667e-05, 'epoch': 2.09}                                                                                                                   
{'loss': 0.3821, 'grad_norm': 11.433417320251465, 'learning_rate': 5.24822695035461e-05, 'epoch': 2.3}                                                                                                                     
{'loss': 0.3925, 'grad_norm': 9.021378517150879, 'learning_rate': 3.829787234042553e-05, 'epoch': 2.51}                                                                                                                    
{'loss': 0.4029, 'grad_norm': 12.193809509277344, 'learning_rate': 2.4113475177304965e-05, 'epoch': 2.72}                                                                                                                  
{'loss': 0.4031, 'grad_norm': 10.77366828918457, 'learning_rate': 9.929078014184398e-06, 'epoch': 2.93}  


학습결과로 추론해본 결과
max_new_tokens=50(답변 길이를 여유있게) temperature=0.7(다양성) repetition_penalty=1.2(같은 단어 반복 방지 강화) top_p=0.9(단어 누적 확률 임계값) do_sample=True(랜덤성)

입력 조건: 타입: 전사, 성격: 존칭형, 호감도: 매우높음, 방문: 단골, 이전결과: 대성공, 상성: 좋음
모험가 답변: 안녕하세요! 저번 검 덕분에 크게 승리했습니다. 감사합니다.

입력 조건: 타입: 도적, 성격: 하대형, 호감도: 매우낮음, 방문: 초면, 이전결과: 실패, 상성: 나쁨
모험가 답변: 크흠. 저번 단검은 좀 부실했어. 튼튼하고 날이 날카로운 걸로 줘 봐.

입력 조건: 타입: 마법사, 성격: 단답형, 호감도: 낮음, 방문: 아는사이, 이전결과: 성공, 상성: 보통
모험가 답변: 단검. 빌려줘.

2차 재추론
max_new_tokens=100 temperature=0.85 repetition_penalty=1.5 top_p=0.9 do_sample=True

입력 조건: 타입: 전사, 성격: 존칭형, 호감도: 매우높음, 방문: 단골, 이전결과: 대성공, 상성: 좋음
모험가 답변: 안녕합니다! 저번 검 덕분에 승리했습니다만용 감사드립니다. 오늘도 부탁드리겠습니까?

입력 조건: 타입: 도적, 성격: 하대형, 호감도: 매우낮음, 방문: 초면, 이전결과: 실패, 상성: 나쁨
모험가 답변: 크흠! 저번엔 운이 없어서 failure였지? 이번에는 좀 더 좋다야!!

입력 조건: 타입: 마법사, 성격: 단답형, 호감도: 낮음, 방문: 아는사이, 이전결과: 성공, 상성: 보통
모험가 답변: 지팡이 줘. 저번 것보다 좋다.

3차 재추론
max_new_tokens=60 temperature=0.5 repetition_penalty=1.2 top_p=0.9 do_sample=False

입력 조건: 타입: 전사, 성격: 존칭형, 호감도: 매우높음, 방문: 단골, 이전결과: 대성공, 상성: 좋음
모험가 답변: 안녕하십니까! 저번 검 덕분에 성공했습니다. 오늘도 부탁드립니다!

입력 조건: 타입: 도적, 성격: 하대형, 호감도: 매우낮음, 방문: 초면, 이전결과: 실패, 상성: 나쁨
모험가 답변: 야! 저번 단검은 뭐였지? 이번엔 더 좋은 거 줘봐.

입력 조건: 타입: 마법사, 성격: 단답형, 호감도: 낮음, 방문: 아는사이, 이전결과: 성공, 상성: 보통
모험가 답변: 지팡이. 저번 거 좋았어. 오늘도 같아.

4차 재추론
max_new_tokens=60 temperature=0.5 repetition_penalty=1.2 top_p=0.9 do_sample=True
입력 조건: 타입: 전사, 성격: 존칭형, 호감도: 매우높음, 방문: 단골, 이전결과: 대성공, 상성: 좋음
모험가 답변: 안녕하세요! 저번 단검 덕분에 큰 성공했습니다! 오늘도 부탁드립니다.

입력 조건: 타입: 도적, 성격: 하대형, 호감도: 매우낮음, 방문: 초면, 이전결과: 실패, 상성: 나쁨
모험가 답변: 야! 저번 단검은 뭐였지? 이번엔 좀 더 튼튼한 거 줘.

입력 조건: 타입: 마법사, 성격: 단답형, 호감도: 낮음, 방문: 아는사이, 이전결과: 성공, 상성: 보통
모험가 답변: 지팡이. 저번 것처럼 튼튼하고.

5차 재추론
max_new_tokens=60 temperature=0.3 repetition_penalty=1.1 top_p=0.7 do_sample=True
입력 조건: 타입: 전사, 성격: 존칭형, 호감도: 매우높음, 방문: 단골, 이전결과: 대성공, 상성: 좋음
모험가 답변: 안녕하십니까! 저번 검 덕분에 성공했습니다. 오늘도 부탁드립니다!

입력 조건: 타입: 도적, 성격: 하대형, 호감도: 매우낮음, 방문: 초면, 이전결과: 실패, 상성: 나쁨
모험가 답변: 야! 저번 단검은 너무 무거웠어. 좀 가벼운 거 없어?

입력 조건: 타입: 마법사, 성격: 단답형, 호감도: 낮음, 방문: 아는사이, 이전결과: 성공, 상성: 보통
모험가 답변: 지팡이. 저번 거 좋았어.


[품질 개선 계획]
현상: 입력 변수(lastTypeMatch)의 모호성으로 인한 모델의 판단 저하 및 근거 없는 정보 생성(Hallucination) 확인.
원인: 훈련 데이터 내 특정 단어의 빈도 불균형 및 짧은 학습 단계로 인한 문맥 파악 미흡.
대책: 데이터 증강(Data Augmentation)을 통해 직업별 고유 키워드 매칭을 강화하고, LoRA Rank를 상향하여 모델의 표현력을 개선할 예정.
또한 데이터 구조를 변경해 한국어 학습에 더 특화되도록 변경.